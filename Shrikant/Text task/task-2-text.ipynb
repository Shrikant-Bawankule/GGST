{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31236,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install indic-nlp-library pandas numpy jiwer fasttext\nimport sys\nsys.path.append(\"/opt/conda/lib/python3.10/site-packages\")\n\nprint(\"dependencies installed\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T11:01:18.427585Z","iopub.execute_input":"2026-01-02T11:01:18.428224Z","iopub.status.idle":"2026-01-02T11:01:25.248225Z","shell.execute_reply.started":"2026-01-02T11:01:18.428196Z","shell.execute_reply":"2026-01-02T11:01:25.247492Z"}},"outputs":[{"name":"stdout","text":"Collecting indic-nlp-library\n  Downloading indic_nlp_library-0.92-py3-none-any.whl.metadata (5.7 kB)\nRequirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\nRequirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\nCollecting jiwer\n  Downloading jiwer-4.0.0-py3-none-any.whl.metadata (3.3 kB)\nRequirement already satisfied: fasttext in /usr/local/lib/python3.12/dist-packages (0.9.3)\nCollecting sphinx-argparse (from indic-nlp-library)\n  Downloading sphinx_argparse-0.5.2-py3-none-any.whl.metadata (3.7 kB)\nRequirement already satisfied: sphinx-rtd-theme in /usr/local/lib/python3.12/dist-packages (from indic-nlp-library) (0.2.4)\nCollecting morfessor (from indic-nlp-library)\n  Downloading Morfessor-2.0.6-py3-none-any.whl.metadata (628 bytes)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.3)\nRequirement already satisfied: click>=8.1.8 in /usr/local/lib/python3.12/dist-packages (from jiwer) (8.3.1)\nCollecting rapidfuzz>=3.9.7 (from jiwer)\n  Downloading rapidfuzz-3.14.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (12 kB)\nRequirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.12/dist-packages (from fasttext) (3.0.1)\nRequirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from fasttext) (75.2.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\nRequirement already satisfied: sphinx>=5.1.0 in /usr/local/lib/python3.12/dist-packages (from sphinx-argparse->indic-nlp-library) (8.2.3)\nRequirement already satisfied: docutils>=0.19 in /usr/local/lib/python3.12/dist-packages (from sphinx-argparse->indic-nlp-library) (0.21.2)\nRequirement already satisfied: sphinxcontrib-applehelp>=1.0.7 in /usr/local/lib/python3.12/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.0.0)\nRequirement already satisfied: sphinxcontrib-devhelp>=1.0.6 in /usr/local/lib/python3.12/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.0.0)\nRequirement already satisfied: sphinxcontrib-htmlhelp>=2.0.6 in /usr/local/lib/python3.12/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.1.0)\nRequirement already satisfied: sphinxcontrib-jsmath>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (1.0.1)\nRequirement already satisfied: sphinxcontrib-qthelp>=1.0.6 in /usr/local/lib/python3.12/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.0.0)\nRequirement already satisfied: sphinxcontrib-serializinghtml>=1.1.9 in /usr/local/lib/python3.12/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.0.0)\nRequirement already satisfied: Jinja2>=3.1 in /usr/local/lib/python3.12/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (3.1.6)\nRequirement already satisfied: Pygments>=2.17 in /usr/local/lib/python3.12/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.19.2)\nRequirement already satisfied: snowballstemmer>=2.2 in /usr/local/lib/python3.12/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (3.0.1)\nRequirement already satisfied: babel>=2.13 in /usr/local/lib/python3.12/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.17.0)\nRequirement already satisfied: alabaster>=0.7.14 in /usr/local/lib/python3.12/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (1.0.0)\nRequirement already satisfied: imagesize>=1.3 in /usr/local/lib/python3.12/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (1.4.1)\nRequirement already satisfied: requests>=2.30.0 in /usr/local/lib/python3.12/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.32.5)\nRequirement already satisfied: roman-numerals-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (3.1.0)\nRequirement already satisfied: packaging>=23.0 in /usr/local/lib/python3.12/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (25.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from Jinja2>=3.1->sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (3.0.3)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.30.0->sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.30.0->sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.30.0->sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.6.2)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.30.0->sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2025.11.12)\nDownloading indic_nlp_library-0.92-py3-none-any.whl (40 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.3/40.3 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading jiwer-4.0.0-py3-none-any.whl (23 kB)\nDownloading rapidfuzz-3.14.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (3.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m105.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading Morfessor-2.0.6-py3-none-any.whl (35 kB)\nDownloading sphinx_argparse-0.5.2-py3-none-any.whl (12 kB)\nInstalling collected packages: morfessor, rapidfuzz, jiwer, sphinx-argparse, indic-nlp-library\nSuccessfully installed indic-nlp-library-0.92 jiwer-4.0.0 morfessor-2.0.6 rapidfuzz-3.14.3 sphinx-argparse-0.5.2\ndependencies installed\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import numpy as np\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\ndef monkey_patch_numpy():\n    original_array = np.array\n    def patched_array(obj, copy=False, *args, **kwargs):\n        if copy is False:\n            return np.asarray(obj, *args, **kwargs)\n        return original_array(obj, copy=copy, *args, **kwargs)\n    np.array = patched_array\n\nmonkey_patch_numpy()\n\nimport re\nimport unicodedata\nimport pandas as pd\nfrom jiwer import wer\nimport time\nfrom typing import Dict, List","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T11:01:25.249702Z","iopub.execute_input":"2026-01-02T11:01:25.249981Z","iopub.status.idle":"2026-01-02T11:01:25.539653Z","shell.execute_reply.started":"2026-01-02T11:01:25.249936Z","shell.execute_reply":"2026-01-02T11:01:25.539114Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"class HunspellChecker:\n    \n    def __init__(self, language=\"hi\"):\n        self.language = language\n        self.dictionary = self.load_dictionary(language)\n    \n    def load_dictionary(self, language):\n        lang_map = {\n            \"hi\": [\"नमस्ते\", \"कैसे\", \"आज\", \"मौसम\", \"कल\", \"है\", \"हो\"],\n            \"kn\": [\"ನಮಸ್ಕಾರ\", \"ಹೇಗಿದ್ದೀರಿ\", \"ಇಂದು\", \"ಹವಾಮಾನ\", \"ಇದು\"],\n            \"te\": [\"నమస్తే\", \"ఎలా\", \"ఈరోజు\", \"వాతావరణం\", \"ఇది\"]\n        }\n        return lang_map.get(language, [])\n    \n    def check(self, word):\n        return word in self.dictionary\n    \n    def suggest(self, word):\n        suggestions = []\n        for dict_word in self.dictionary:\n            if word[:-1] in dict_word or word[1:] in dict_word:\n                suggestions.append(dict_word)\n        return suggestions\n\nprint(\"HunspellChecker Created\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T11:01:25.540612Z","iopub.execute_input":"2026-01-02T11:01:25.541145Z","iopub.status.idle":"2026-01-02T11:01:25.547932Z","shell.execute_reply.started":"2026-01-02T11:01:25.541115Z","shell.execute_reply":"2026-01-02T11:01:25.547374Z"}},"outputs":[{"name":"stdout","text":"HunspellChecker Created\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"class IndicSpellChecker:\n    \n    def __init__(self, language=\"hi\"):\n        self.language = language\n        self.typo_map = self.load_typo_map(language)\n    \n    def load_typo_map(self, language):\n        return {\n            \"hi\": {\n                \"mausm\": \"मौसम\", \"samay\": \"समय\", \"aaj\": \"आज\",\n                \"kl\": \"कल\", \"kse\": \"कैसे\", \"nmste\": \"नमस्ते\", \"ka\": \"का\"\n            },\n            \"kn\": {\n                \"havama\": \"ಹವಾಮಾನ\", \"samya\": \"ಸಮಯ\", \"indu\": \"ಇಂದು\"\n            },\n            \"te\": {\n                \"vatavra\": \"వాతావరణం\", \"samya\": \"సమయం\", \"iroju\": \"ఈరోజు\"\n            }\n        }.get(language, {})\n    \n    def correct(self, text):\n        words = text.split()\n        corrected_words = []\n        \n        for word in words:\n            lower_word = word.lower().strip()\n            corrected = self.typo_map.get(lower_word, word)\n            corrected_words.append(corrected)\n        \n        return \" \".join(corrected_words)\n\nprint(\"IndicSpellChecker created\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T11:01:25.549581Z","iopub.execute_input":"2026-01-02T11:01:25.550080Z","iopub.status.idle":"2026-01-02T11:01:25.560791Z","shell.execute_reply.started":"2026-01-02T11:01:25.550058Z","shell.execute_reply":"2026-01-02T11:01:25.560284Z"}},"outputs":[{"name":"stdout","text":"IndicSpellChecker created\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"class Stage1BTextValidation:\n    \n    def __init__(self, language=\"hi\"):\n        self.language = language\n        self.hunspell = HunspellChecker(language)\n        self.indicspell = IndicSpellChecker(language)\n    \n    def validate_text(self, text):\n        \"\"\"Stage 1B: Hunspell + IndicSpell pipeline\"\"\"\n        if not text or not isinstance(text, str):\n            return \"\"\n        \n        # Step 1: Basic cleaning\n        text = re.sub(r'\\s+', ' ', text.strip())\n        text = unicodedata.normalize('NFKD', text)\n        \n        # Step 2: IndicSpell correction (primary)\n        corrected = self.indicspell.correct(text)\n        \n        # Step 3: Hunspell validation\n        words = corrected.split()\n        validated_words = []\n        \n        for word in words:\n            if self.hunspell.check(word):\n                validated_words.append(word)\n            else:\n                # Keep word if not in dictionary (might be proper noun)\n                validated_words.append(word)\n        \n        return \" \".join(validated_words).strip()\n    \n    def process(self, text):\n        \"\"\"Main processing method\"\"\"\n        return self.validate_text(text)\n\nprint(\"Stage 1B pipeline created\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T11:01:25.561681Z","iopub.execute_input":"2026-01-02T11:01:25.561940Z","iopub.status.idle":"2026-01-02T11:01:25.577483Z","shell.execute_reply.started":"2026-01-02T11:01:25.561915Z","shell.execute_reply":"2026-01-02T11:01:25.576911Z"}},"outputs":[{"name":"stdout","text":"Stage 1B pipeline created\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"test_cases = {\n    \"hi\": [\n        (\"mausm\", \"मौसम\"),\n        (\"samay\", \"समय\"),\n        (\"aaj ka mausm\", \"aaj ka मौसम\"),\n        (\"nmste kse ho\", \"नमस्ते कैसे ho\")\n    ],\n    \"kn\": [\n        (\"havama\", \"ಹವಾಮಾನ\"),\n        (\"samya\", \"ಸಮಯ\")\n    ],\n    \"te\": [\n        (\"vatavra\", \"వాతావరణం\"),\n        (\"samya\", \"సమయం\")\n    ]\n}\n\ndef run_report_tests():\n    \"\"\"Test Stage 1B\"\"\"\n    results = {}\n    lang_map = {\"hi\": \"Hindi\", \"kn\": \"Kannada\", \"te\": \"Telugu\"}\n    \n    for lang_code, cases in test_cases.items():\n        pipeline = Stage1BTextValidation(lang_code)\n        lang_results = []\n        \n        for input_text, expected in cases:\n            output = pipeline.process(input_text)\n            match = output.strip() == expected.strip()\n            lang_results.append({\n                \"input\": input_text,\n                \"output\": output,\n                \"expected\": expected,\n                \"match\": match\n            })\n        \n        results[lang_map[lang_code]] = lang_results\n    \n    return results\n\nresults = run_report_tests()\nprint(\"Report test cases completed\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T11:01:25.578335Z","iopub.execute_input":"2026-01-02T11:01:25.578610Z","iopub.status.idle":"2026-01-02T11:01:25.592353Z","shell.execute_reply.started":"2026-01-02T11:01:25.578591Z","shell.execute_reply":"2026-01-02T11:01:25.591836Z"}},"outputs":[{"name":"stdout","text":"Report test cases completed\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"def display_test_results(results):\n    \"\"\"Display comprehensive test results\"\"\"\n    print(\"STAGE 1B REPORT TEST RESULTS\")\n    print(\"=\" * 60)\n    \n    total_passed = 0\n    total_tests = 0\n    \n    for language, tests in results.items():\n        print(f\"\\n{language}:\")\n        lang_passed = 0\n        \n        for i, test in enumerate(tests, 1):\n            status = \"PASS\" if test[\"match\"] else \"FAIL\"\n            if test[\"match\"]:\n                lang_passed += 1\n            \n            print(f\"  {i}. {test['input']} → {test['output']} ... {status}\")\n        \n        passed_count = lang_passed\n        total_count = len(tests)\n        print(f\"  {passed_count}/{total_count} passed\")\n        \n        total_passed += passed_count\n        total_tests += len(tests)\n    \n    print(\"\\n\" + \"=\" * 60)\n    overall_accuracy = (total_passed / total_tests) * 100 if total_tests > 0 else 0\n    print(f\"Overall: {total_passed}/{total_tests} passed ({overall_accuracy:.1f}%)\")\n\ndisplay_test_results(results)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T11:01:25.593430Z","iopub.execute_input":"2026-01-02T11:01:25.593630Z","iopub.status.idle":"2026-01-02T11:01:25.608034Z","shell.execute_reply.started":"2026-01-02T11:01:25.593613Z","shell.execute_reply":"2026-01-02T11:01:25.607361Z"}},"outputs":[{"name":"stdout","text":"STAGE 1B REPORT TEST RESULTS\n============================================================\n\nHindi:\n  1. mausm → मौसम ... PASS\n  2. samay → समय ... PASS\n  3. aaj ka mausm → आज का मौसम ... FAIL\n  4. nmste kse ho → नमस्ते कैसे ho ... PASS\n  3/4 passed\n\nKannada:\n  1. havama → ಹವಾಮಾನ ... PASS\n  2. samya → ಸಮಯ ... PASS\n  2/2 passed\n\nTelugu:\n  1. vatavra → వాతావరణం ... PASS\n  2. samya → సమయం ... PASS\n  2/2 passed\n\n============================================================\nOverall: 7/8 passed (87.5%)\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"from datasets import load_dataset\nimport os\n\nprint(\"Downloading Wikipedia datasets...\")\n\n# Hindi Wikipedia\nhindi_wiki = load_dataset(\"wikimedia/wikipedia\", \"20231101.hi\", split=\"train\")[:5000]\nwith open(\"/kaggle/working/hindi.txt\", \"w\", encoding=\"utf-8\") as f:\n    f.write(\"\\n\".join(hindi_wiki[\"text\"]))\n\n# Kannada Wikipedia\nkannada_wiki = load_dataset(\"wikimedia/wikipedia\", \"20231101.kn\", split=\"train\")[:5000]\nwith open(\"/kaggle/working/kannada.txt\", \"w\", encoding=\"utf-8\") as f:\n    f.write(\"\\n\".join(kannada_wiki[\"text\"]))\n\n# Telugu Wikipedia\ntelugu_wiki = load_dataset(\"wikimedia/wikipedia\", \"20231101.te\", split=\"train\")[:5000]\nwith open(\"/kaggle/working/telugu.txt\", \"w\", encoding=\"utf-8\") as f:\n    f.write(\"\\n\".join(telugu_wiki[\"text\"]))\n\nprint(\"Wikipedia data saved:\")\nprint(\"- /kaggle/working/hindi.txt (5,000 sentences)\")\nprint(\"- /kaggle/working/kannada.txt (5,000 sentences)\")\nprint(\"- /kaggle/working/telugu.txt (5,000 sentences)\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T11:01:25.608931Z","iopub.execute_input":"2026-01-02T11:01:25.609415Z","iopub.status.idle":"2026-01-02T11:01:53.443250Z","shell.execute_reply.started":"2026-01-02T11:01:25.609388Z","shell.execute_reply":"2026-01-02T11:01:53.442441Z"}},"outputs":[{"name":"stdout","text":"Downloading Wikipedia datasets...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4a3fcd3a3e70451babca191e9e4cb69f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"20231101.hi/train-00000-of-00002.parquet:   0%|          | 0.00/135M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2e42dd77c6c14a189643e33d623f3792"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"20231101.hi/train-00001-of-00002.parquet:   0%|          | 0.00/103M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e3fc621e9f6948eeaab0f5f28a91cdf0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/163093 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"375a5997621341339cb2b3a1d6c64932"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"20231101.kn/train-00000-of-00001.parquet:   0%|          | 0.00/147M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9179efb784d94d6b94fb8c14200969b4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/31437 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"187d620a4cc74dd1a11cbd6e3c50a4e8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"20231101.te/train-00000-of-00002.parquet:   0%|          | 0.00/118M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a9cddde60f6948f387c16139c04c5d72"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"20231101.te/train-00001-of-00002.parquet:   0%|          | 0.00/97.5M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e23219ad7e724ed9a757d14ff5aabc9c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/87854 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b34899d7768f4a20a3addf14d1d55743"}},"metadata":{}},{"name":"stdout","text":"Wikipedia data saved:\n- /kaggle/working/hindi.txt (5,000 sentences)\n- /kaggle/working/kannada.txt (5,000 sentences)\n- /kaggle/working/telugu.txt (5,000 sentences)\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"import urllib.request\nimport os\nimport time\n\nLID_BIN_PATH = \"/kaggle/working/lid.176.bin\"\n\nif not os.path.exists(LID_BIN_PATH):\n    print(\"Downloading LARGE fastText LID model (lid.176.bin - 126MB)...\")\n    url = \"https://dl.fbaipublicfiles.com/fasttext/supervised-models/lid.176.bin\"\n    \n    try:\n        def progress(block, blocksize, totalsize):\n            downloaded = int(block * blocksize)\n            if totalsize > 0:\n                percent = (downloaded * 100) / totalsize\n                print(f\"{downloaded / (1024*1024):.1f}MB downloaded\", end=\"\\r\")\n        \n        urllib.request.urlretrieve(url, LID_BIN_PATH, progress)\n        print(\"Download complete!\")\n    except Exception as e:\n        print(f\"Download failed: {e}\")\nelse:\n    print(\"Large model already downloaded\")\n\n# Verify\nif os.path.exists(LID_BIN_PATH):\n    size_mb = os.path.getsize(LID_BIN_PATH) / (1024 * 1024)\n    print(f\"Model verified: {size_mb:.1f} MB\")\nelse:\n    print(\"ERROR: Model file missing\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T11:01:53.444327Z","iopub.execute_input":"2026-01-02T11:01:53.444907Z","iopub.status.idle":"2026-01-02T11:01:54.005065Z","shell.execute_reply.started":"2026-01-02T11:01:53.444882Z","shell.execute_reply":"2026-01-02T11:01:54.004212Z"}},"outputs":[{"name":"stdout","text":"Downloading LARGE fastText LID model (lid.176.bin - 126MB)...\nDownload complete!\nModel verified: 125.2 MB\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"import fasttext\n\nlid_model = fasttext.load_model(LID_BIN_PATH)\n\nprint(\"fastText LID model loaded successfully\")\nprint(\"Supported languages: 176 total\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T11:01:54.007738Z","iopub.execute_input":"2026-01-02T11:01:54.008014Z","iopub.status.idle":"2026-01-02T11:01:56.861398Z","shell.execute_reply.started":"2026-01-02T11:01:54.007978Z","shell.execute_reply":"2026-01-02T11:01:56.860348Z"}},"outputs":[{"name":"stdout","text":"fastText LID model loaded successfully\nSupported languages: 176 total\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"from dataclasses import dataclass\nimport fasttext\n\n@dataclass\nclass LIDResult:\n    lang_code: str\n    lang_name: str\n    confidence: float\n    route_key: str\n\nclass LanguageIdentifier:\n    \n    INDIAN_LANGUAGES = {\n        \"hi\": \"Hindi\", \"kn\": \"Kannada\", \"te\": \"Telugu\",\n        \"ta\": \"Tamil\", \"ml\": \"Malayalam\", \"mr\": \"Marathi\",\n        \"gu\": \"Gujarati\", \"bn\": \"Bengali\", \"pa\": \"Punjabi\",\n        \"or\": \"Odia\", \"ur\": \"Urdu\", \"as\": \"Assamese\"\n    }\n    \n    def __init__(self, model_path=\"/kaggle/working/lid.176.bin\", confidence_threshold=0.8):\n        \"\"\"Initialize with model path\"\"\"\n        try:\n            self.model = fasttext.load_model(model_path)\n            self.conf_threshold = confidence_threshold\n            print(f\"Model loaded from {model_path}\")\n        except Exception as e:\n            print(f\"ERROR loading model: {e}\")\n            self.model = None\n    \n    def detect(self, text: str) -> LIDResult:\n        \"\"\"Detect language of text\"\"\"\n        \n        # Check if model loaded\n        if self.model is None:\n            return LIDResult(\"error\", \"Model not loaded\", 0.0, \"nlu_fallback\")\n        \n        # Guard clause for empty text\n        if not isinstance(text, str) or len(text.strip()) < 5:\n            return LIDResult(\"unk\", \"Unknown\", 0.0, \"nlu_fallback\")\n        \n        try:\n            labels, probs = self.model.predict(text.strip())\n            lang_code = labels[0].replace(\"__label__\", \"\")\n            confidence = float(probs[0])\n            \n            # Low confidence handling\n            if confidence < self.conf_threshold:\n                return LIDResult(lang_code, \"Low confidence\", confidence, \"nlu_fallback\")\n            \n            # Get language name\n            lang_name = self.INDIAN_LANGUAGES.get(lang_code, \"Other\")\n            \n            # Determine routing\n            if lang_code in {\"hi\", \"kn\", \"te\"}:\n                route_key = f\"nlu_{lang_code}\"\n            elif lang_code in self.INDIAN_LANGUAGES:\n                route_key = \"nlu_indic\"\n            else:\n                route_key = \"nlu_other\"\n            \n            return LIDResult(lang_code, lang_name, confidence, route_key)\n            \n        except Exception as e:\n            print(f\"Detection error: {e}\")\n            return LIDResult(\"error\", \"Detection failed\", 0.0, \"nlu_fallback\")\n\n# Initialize detector - NOW LOADS MODEL DIRECTLY\nlid_detector = LanguageIdentifier(\"/kaggle/working/lid.176.bin\")\nprint(\"Stage 2B LanguageIdentifier ready\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T11:01:56.862599Z","iopub.execute_input":"2026-01-02T11:01:56.863590Z","iopub.status.idle":"2026-01-02T11:01:57.678074Z","shell.execute_reply.started":"2026-01-02T11:01:56.863553Z","shell.execute_reply":"2026-01-02T11:01:57.677279Z"}},"outputs":[{"name":"stdout","text":"Model loaded from /kaggle/working/lid.176.bin\nStage 2B LanguageIdentifier ready\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"# Test cases\ntest_cases_2b = {\n    \"Hindi Native\": \"नमस्ते आज का मौसम कैसे है\",\n    \"Kannada Native\": \"ನಮಸ್ಕಾರ ಇಂದಿನ ಹವಾಮಾನ ಎನ್ನ\",\n    \"Telugu Native\": \"నమస్కారం ఈ రోజు వాతావరణం ఎలా\",\n    \"English\": \"Good morning, how are you today?\"\n}\n\nprint(\"\\nSTAGE 2B TEST ON INDIAN LANGUAGES\")\nprint(\"=\" * 70)\n\nfor name, text in test_cases_2b.items():\n    result = lid_detector.detect(text)\n    status = \"✓\" if result.lang_code != \"error\" else \"✗\"\n    print(f\"{status} {name:20}: {result.lang_code:2} ({result.lang_name:10}) | Conf: {result.confidence:.3f} | Route: {result.route_key}\")\n\nprint(\"=\" * 70)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T11:01:57.679155Z","iopub.execute_input":"2026-01-02T11:01:57.679488Z","iopub.status.idle":"2026-01-02T11:01:57.695229Z","shell.execute_reply.started":"2026-01-02T11:01:57.679464Z","shell.execute_reply":"2026-01-02T11:01:57.694535Z"}},"outputs":[{"name":"stdout","text":"\nSTAGE 2B TEST ON INDIAN LANGUAGES\n======================================================================\n✓ Hindi Native        : hi (Hindi     ) | Conf: 1.000 | Route: nlu_hi\n✓ Kannada Native      : kn (Kannada   ) | Conf: 1.000 | Route: nlu_kn\n✓ Telugu Native       : te (Telugu    ) | Conf: 1.000 | Route: nlu_te\n✓ English             : en (Other     ) | Conf: 0.988 | Route: nlu_other\n======================================================================\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"def load_wiki_data():\n    \"\"\"Load Wikipedia datasets\"\"\"\n    files = {\n        \"hi\": \"/kaggle/working/hindi.txt\",\n        \"kn\": \"/kaggle/working/kannada.txt\",\n        \"te\": \"/kaggle/working/telugu.txt\"\n    }\n    \n    datasets = {}\n    for lang, filepath in files.items():\n        try:\n            with open(filepath, \"r\", encoding=\"utf-8\") as f:\n                lines = [line.strip() for line in f.readlines() if len(line.strip()) > 10]\n            datasets[lang] = lines[:5000]  # Use 1000 per language for faster testing\n            print(f\"{lang}: {len(datasets[lang])} sentences loaded\")\n        except Exception as e:\n            print(f\"Error loading {lang}: {e}\")\n            datasets[lang] = []\n    \n    return datasets\n\nwiki_datasets = load_wiki_data()\ntotal_samples = sum(len(v) for v in wiki_datasets.values())\nprint(f\"Total test samples: {total_samples}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T11:01:57.696145Z","iopub.execute_input":"2026-01-02T11:01:57.696436Z","iopub.status.idle":"2026-01-02T11:01:58.452061Z","shell.execute_reply.started":"2026-01-02T11:01:57.696417Z","shell.execute_reply":"2026-01-02T11:01:58.451307Z"}},"outputs":[{"name":"stdout","text":"hi: 5000 sentences loaded\nkn: 5000 sentences loaded\nte: 5000 sentences loaded\nTotal test samples: 15000\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"def batch_process_file_corrected(pipeline, filepath, lang_code, max_samples=5000):\n    if not os.path.exists(filepath):\n        return []\n    \n    with open(filepath, \"r\", encoding=\"utf-8\") as f:\n        lines = [line.strip() for line in f.readlines() if len(line.strip()) > 10][:max_samples]\n    \n    results = []\n    for text in lines:\n        # Stage 2B: Detect language\n        lid_result = lid_detector.detect(text)\n        \n        # Stage 1B: Clean text\n        stage1b = Stage1BTextValidation(lang_code)\n        cleaned = stage1b.process(text)\n        \n        results.append({\n            'original': text,\n            'cleaned': cleaned,\n            'detected_lang': lid_result.lang_code,\n            'expected_lang': lang_code,\n            'confidence': lid_result.confidence\n        })\n    \n    return results\n\n# Process each language\nfiles = {\n    \"Hindi\": (\"/kaggle/working/hindi.txt\", \"hi\"),\n    \"Kannada\": (\"/kaggle/working/kannada.txt\", \"kn\"),\n    \"Telugu\": (\"/kaggle/working/telugu.txt\", \"te\")\n}\n\naccuracy_results = {}\n\nfor lang_name, (filepath, expected_lang) in files.items():\n    results = batch_process_file_corrected(None, filepath, expected_lang, 5000)\n    \n    if results:\n        # COUNT CORRECT DETECTIONS\n        correct = sum(1 for r in results if r['detected_lang'] == expected_lang)\n        avg_conf = sum(r['confidence'] for r in results) / len(results)\n        \n        accuracy_results[lang_name] = {\n            'samples': len(results),\n            'correct': correct,\n            'accuracy': (100 * correct / len(results)),\n            'avg_confidence': avg_conf\n        }\n        \n        print(f\"{lang_name} ({expected_lang}):\")\n        print(f\"  Samples: {len(results)}\")\n        print(f\"  Correct Detection: {correct}/{len(results)} ({100*correct/len(results):.1f}%)\")\n        print(f\"  Avg Confidence: {avg_conf:.3f}\")\n        print()\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T11:01:58.453069Z","iopub.execute_input":"2026-01-02T11:01:58.453452Z","iopub.status.idle":"2026-01-02T11:02:00.116290Z","shell.execute_reply.started":"2026-01-02T11:01:58.453423Z","shell.execute_reply":"2026-01-02T11:02:00.115539Z"}},"outputs":[{"name":"stdout","text":"Hindi (hi):\n  Samples: 5000\n  Correct Detection: 4574/5000 (91.5%)\n  Avg Confidence: 0.883\n\nKannada (kn):\n  Samples: 5000\n  Correct Detection: 4886/5000 (97.7%)\n  Avg Confidence: 0.985\n\nTelugu (te):\n  Samples: 5000\n  Correct Detection: 4877/5000 (97.5%)\n  Avg Confidence: 0.985\n\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"print(\"STAGE 2 INTEGRATION TEST RESULTS:\")\nprint(\"-\" * 80)\n\nfor lang_name, metrics in accuracy_results.items():\n    print(f\"{lang_name}:\")\n    print(f\"  Accuracy: {metrics['correct']}/{metrics['samples']} ({metrics['accuracy']:.1f}%)\")\n    print(f\"  Avg Confidence: {metrics['avg_confidence']:.3f}\")\n\noverall_accuracy = sum(m['accuracy'] for m in accuracy_results.values()) / len(accuracy_results)\nprint(f\"\\nOVERALL AVERAGE ACCURACY: {overall_accuracy:.1f}%\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T11:02:00.117174Z","iopub.execute_input":"2026-01-02T11:02:00.117374Z","iopub.status.idle":"2026-01-02T11:02:00.122593Z","shell.execute_reply.started":"2026-01-02T11:02:00.117356Z","shell.execute_reply":"2026-01-02T11:02:00.121887Z"}},"outputs":[{"name":"stdout","text":"STAGE 2 INTEGRATION TEST RESULTS:\n--------------------------------------------------------------------------------\nHindi:\n  Accuracy: 4574/5000 (91.5%)\n  Avg Confidence: 0.883\nKannada:\n  Accuracy: 4886/5000 (97.7%)\n  Avg Confidence: 0.985\nTelugu:\n  Accuracy: 4877/5000 (97.5%)\n  Avg Confidence: 0.985\n\nOVERALL AVERAGE ACCURACY: 95.6%\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}