{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "zip_file_path = '/content/hi_test_dataset.zip'\n",
        "extraction_path = '/content/'\n",
        "\n",
        "os.makedirs(extraction_path, exist_ok=True)\n",
        "\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extraction_path)\n",
        "\n",
        "print(f\"'{zip_file_path}' extracted to '{extraction_path}'\")\n",
        "print(f\"Contents of '{extraction_path}':\")\n",
        "print(os.listdir(extraction_path))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KTx6uNFUCHYl",
        "outputId": "adda81c0-615b-4ba0-e51d-6fc1b3a4c364"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'/content/hi_test_dataset.zip' extracted to '/content/'\n",
            "Contents of '/content/':\n",
            "['.config', 'hi_test_dataset.zip', 'hi_test_dataset', 'sample_data']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OObeHbl6NrMb",
        "outputId": "a99a139d-d883-4cbe-a1a9-6607d7e84234"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Base dir exists: True\n",
            "Base dir contents: ['audio+transcripts']\n",
            "\n",
            "Sub dir exists: True\n",
            "Sub dir contents (first 15): ['common_voice_hi_27762774.mp3', 'common_voice_hi_26044297.mp3', 'common_voice_hi_24258388.mp3', 'common_voice_hi_26018159.mp3', 'common_voice_hi_27408369.mp3', 'common_voice_hi_27372138.mp3', 'common_voice_hi_27371837.mp3', 'common_voice_hi_24360601.mp3', 'common_voice_hi_27407935.mp3', 'common_voice_hi_32249437.mp3', 'common_voice_hi_26988410.mp3', 'common_voice_hi_26120121.mp3', 'common_voice_hi_26120192.mp3', 'common_voice_hi_24829334.mp3', 'common_voice_hi_27565446.mp3']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "BASE_DIR = \"hi_test_dataset\"\n",
        "\n",
        "print(\"Base dir exists:\", os.path.exists(BASE_DIR))\n",
        "print(\"Base dir contents:\", os.listdir(BASE_DIR))\n",
        "\n",
        "SUB_DIR = os.path.join(BASE_DIR, \"audio+transcripts\")\n",
        "\n",
        "print(\"\\nSub dir exists:\", os.path.exists(SUB_DIR))\n",
        "print(\"Sub dir contents (first 15):\", os.listdir(SUB_DIR)[:15])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torchcodec"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K0iHd_CECaz2",
        "outputId": "cc2cff45-1b3b-407a-85b6-40463db3229e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchcodec\n",
            "  Downloading torchcodec-0.9.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (11 kB)\n",
            "Downloading torchcodec-0.9.1-cp312-cp312-manylinux_2_28_x86_64.whl (2.1 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m75.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torchcodec\n",
            "Successfully installed torchcodec-0.9.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TboBiZGaNrI_",
        "outputId": "936afa1c-69e2-4fb3-ec82-bc78ad2ca3ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing file: hi_test_dataset/audio+transcripts/common_voice_hi_27762774.mp3\n",
            "Loaded successfully\n",
            "Waveform shape: torch.Size([1, 150912])\n",
            "Sample rate: 32000\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torchaudio\n",
        "\n",
        "DATA_DIR = \"hi_test_dataset/audio+transcripts\"\n",
        "\n",
        "# pick one mp3 file\n",
        "mp3_files = [f for f in os.listdir(DATA_DIR) if f.lower().endswith(\".mp3\")]\n",
        "test_file = mp3_files[0]\n",
        "\n",
        "test_path = os.path.join(DATA_DIR, test_file)\n",
        "print(\"Testing file:\", test_path)\n",
        "\n",
        "waveform, sr = torchaudio.load(test_path)\n",
        "\n",
        "print(\"Loaded successfully\")\n",
        "print(\"Waveform shape:\", waveform.shape)\n",
        "print(\"Sample rate:\", sr)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "shU8mPjONrGy",
        "outputId": "010217fe-5ca4-433c-bfe8-a35fd50710bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved file exists: True\n",
            "Saved at: /content/processed_wav/TEST_RESAMPLED.wav\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torchaudio\n",
        "\n",
        "DATA_DIR = \"hi_test_dataset/audio+transcripts\"\n",
        "OUT_DIR = \"/content/processed_wav\"\n",
        "\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "\n",
        "test_file = \"common_voice_hi_24258388.mp3\"\n",
        "in_path = os.path.join(DATA_DIR, test_file)\n",
        "out_path = os.path.join(OUT_DIR, \"TEST_RESAMPLED.wav\")\n",
        "\n",
        "# load\n",
        "waveform, sr = torchaudio.load(in_path)\n",
        "\n",
        "# mono (safety)\n",
        "if waveform.shape[0] > 1:\n",
        "    waveform = waveform.mean(dim=0, keepdim=True)\n",
        "\n",
        "# resample to 16k\n",
        "if sr != 16000:\n",
        "    waveform = torchaudio.functional.resample(waveform, sr, 16000)\n",
        "\n",
        "# save\n",
        "torchaudio.save(out_path, waveform, 16000)\n",
        "\n",
        "print(\"Saved file exists:\", os.path.exists(out_path))\n",
        "print(\"Saved at:\", out_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install silero-vad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "OCQ0Q3VsCovh",
        "outputId": "ae851a16-7a2b-44df-fe3d-957f389bd10b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting silero-vad\n",
            "  Downloading silero_vad-6.2.0-py3-none-any.whl.metadata (9.2 kB)\n",
            "Collecting onnxruntime>=1.16.1 (from silero-vad)\n",
            "  Downloading onnxruntime-1.23.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from silero-vad) (25.0)\n",
            "Requirement already satisfied: torch>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from silero-vad) (2.9.0+cu126)\n",
            "Requirement already satisfied: torchaudio>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from silero-vad) (2.9.0+cu126)\n",
            "Collecting coloredlogs (from onnxruntime>=1.16.1->silero-vad)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.16.1->silero-vad) (25.9.23)\n",
            "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.16.1->silero-vad) (2.0.2)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.16.1->silero-vad) (5.29.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.16.1->silero-vad) (1.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->silero-vad) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->silero-vad) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->silero-vad) (75.2.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->silero-vad) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->silero-vad) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->silero-vad) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->silero-vad) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->silero-vad) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->silero-vad) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->silero-vad) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->silero-vad) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->silero-vad) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->silero-vad) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->silero-vad) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->silero-vad) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->silero-vad) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->silero-vad) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->silero-vad) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->silero-vad) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->silero-vad) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->silero-vad) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12.0->silero-vad) (3.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->onnxruntime>=1.16.1->silero-vad) (1.3.0)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.16.1->silero-vad)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.12.0->silero-vad) (3.0.3)\n",
            "Downloading silero_vad-6.2.0-py3-none-any.whl (6.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m76.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.23.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (17.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.4/17.4 MB\u001b[0m \u001b[31m98.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: humanfriendly, coloredlogs, onnxruntime, silero-vad\n",
            "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnxruntime-1.23.2 silero-vad-6.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2M7SpcysNrEj",
        "outputId": "b7e856a5-85d5-4811-8678-58f6e156c368"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VAD segments: [{'start': 7712, 'end': 76768}]\n",
            "Saved VAD file exists: True\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from silero_vad import load_silero_vad, get_speech_timestamps\n",
        "\n",
        "# load model\n",
        "vad_model = load_silero_vad()\n",
        "\n",
        "# input paths\n",
        "DATA_DIR = \"/content/hi_test_dataset/audio+transcripts\"\n",
        "OUT_DIR = \"/content/processed_wav\"\n",
        "\n",
        "test_file = \"common_voice_hi_24258388.mp3\"\n",
        "in_path = os.path.join(DATA_DIR, test_file)\n",
        "out_path = os.path.join(OUT_DIR, \"TEST_VAD.wav\")\n",
        "\n",
        "# load & resample\n",
        "waveform, sr = torchaudio.load(in_path)\n",
        "\n",
        "if waveform.shape[0] > 1:\n",
        "    waveform = waveform.mean(dim=0, keepdim=True)\n",
        "\n",
        "if sr != 16000:\n",
        "    waveform = torchaudio.functional.resample(waveform, sr, 16000)\n",
        "    sr = 16000\n",
        "\n",
        "# VERY GENTLE VAD (for short Common Voice clips)\n",
        "speech_ts = get_speech_timestamps(\n",
        "    waveform,\n",
        "    vad_model,\n",
        "    sampling_rate=16000,\n",
        "    threshold=0.2,\n",
        "    min_speech_duration_ms=50,\n",
        "    min_silence_duration_ms=300\n",
        ")\n",
        "\n",
        "print(\"VAD segments:\", speech_ts)\n",
        "\n",
        "if len(speech_ts) == 0:\n",
        "    print(\"No speech detected by VAD\")\n",
        "else:\n",
        "    speech_audio = torch.cat(\n",
        "        [waveform[:, s[\"start\"]:s[\"end\"]] for s in speech_ts],\n",
        "        dim=1\n",
        "    )\n",
        "\n",
        "    torchaudio.save(out_path, speech_audio, 16000)\n",
        "    print(\"Saved VAD file exists:\", os.path.exists(out_path))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ngD4dvLENq_J",
        "outputId": "cc22973a-2aa0-4b65-987b-e48ab622630d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total mp3 files: 100\n",
            "Saved: common_voice_hi_27762774.wav\n",
            "Saved: common_voice_hi_26044297.wav\n",
            "Saved: common_voice_hi_24258388.wav\n",
            "Saved: common_voice_hi_26018159.wav\n",
            "Saved: common_voice_hi_27408369.wav\n",
            "Saved: common_voice_hi_27372138.wav\n",
            "Saved: common_voice_hi_27371837.wav\n",
            "Saved: common_voice_hi_24360601.wav\n",
            "Saved: common_voice_hi_27407935.wav\n",
            "Saved: common_voice_hi_32249437.wav\n",
            "Saved: common_voice_hi_26988410.wav\n",
            "Saved: common_voice_hi_26120121.wav\n",
            "Saved: common_voice_hi_26120192.wav\n",
            "Saved: common_voice_hi_24829334.wav\n",
            "Saved: common_voice_hi_27565446.wav\n",
            "Saved: common_voice_hi_26044000.wav\n",
            "Saved: common_voice_hi_24225355.wav\n",
            "Saved: common_voice_hi_24359434.wav\n",
            "Saved: common_voice_hi_25215256.wav\n",
            "Saved: common_voice_hi_26326389.wav\n",
            "Saved: common_voice_hi_26955587.wav\n",
            "Saved: common_voice_hi_26040841.wav\n",
            "Saved: common_voice_hi_26203988.wav\n",
            "Saved: common_voice_hi_26202875.wav\n",
            "Saved: common_voice_hi_25288730.wav\n",
            "Saved: common_voice_hi_25204281.wav\n",
            "Saved: common_voice_hi_24974881.wav\n",
            "Saved: common_voice_hi_23795243.wav\n",
            "Saved: common_voice_hi_26007599.wav\n",
            "Saved: common_voice_hi_27408206.wav\n",
            "Saved: common_voice_hi_25038047.wav\n",
            "Saved: common_voice_hi_26351532.wav\n",
            "Saved: common_voice_hi_24386188.wav\n",
            "Saved: common_voice_hi_26358115.wav\n",
            "Saved: common_voice_hi_26044108.wav\n",
            "Saved: common_voice_hi_29513535.wav\n",
            "Saved: common_voice_hi_24969673.wav\n",
            "Saved: common_voice_hi_26033321.wav\n",
            "Saved: common_voice_hi_39589259.wav\n",
            "Saved: common_voice_hi_23849316.wav\n",
            "Saved: common_voice_hi_25323105.wav\n",
            "Saved: common_voice_hi_26358181.wav\n",
            "Saved: common_voice_hi_24258385.wav\n",
            "Saved: common_voice_hi_24758462.wav\n",
            "Saved: common_voice_hi_27393985.wav\n",
            "Saved: common_voice_hi_25233734.wav\n",
            "Saved: common_voice_hi_24386850.wav\n",
            "Saved: common_voice_hi_27913614.wav\n",
            "Saved: common_voice_hi_24258399.wav\n",
            "Saved: common_voice_hi_27389441.wav\n",
            "Saved: common_voice_hi_27501564.wav\n",
            "Saved: common_voice_hi_26033071.wav\n",
            "Saved: common_voice_hi_26007783.wav\n",
            "Saved: common_voice_hi_26033032.wav\n",
            "Saved: common_voice_hi_26202836.wav\n",
            "Saved: common_voice_hi_26115329.wav\n",
            "Saved: common_voice_hi_27517933.wav\n",
            "Saved: common_voice_hi_25543854.wav\n",
            "Saved: common_voice_hi_27466295.wav\n",
            "Saved: common_voice_hi_26131881.wav\n",
            "Saved: common_voice_hi_27408341.wav\n",
            "Saved: common_voice_hi_26204192.wav\n",
            "Saved: common_voice_hi_26946732.wav\n",
            "Saved: common_voice_hi_24228330.wav\n",
            "Saved: common_voice_hi_26115309.wav\n",
            "Saved: common_voice_hi_23937537.wav\n",
            "Saved: common_voice_hi_35151696.wav\n",
            "Saved: common_voice_hi_23809919.wav\n",
            "Saved: common_voice_hi_24386803.wav\n",
            "Saved: common_voice_hi_24956011.wav\n",
            "Saved: common_voice_hi_26142981.wav\n",
            "Saved: common_voice_hi_23849322.wav\n",
            "Saved: common_voice_hi_27517718.wav\n",
            "Saved: common_voice_hi_27005547.wav\n",
            "Saved: common_voice_hi_27389392.wav\n",
            "Saved: common_voice_hi_26326613.wav\n",
            "Saved: common_voice_hi_26351119.wav\n",
            "Saved: common_voice_hi_25269028.wav\n",
            "Saved: common_voice_hi_26021808.wav\n",
            "Saved: common_voice_hi_24957814.wav\n",
            "Saved: common_voice_hi_24026319.wav\n",
            "Saved: common_voice_hi_25323066.wav\n",
            "Saved: common_voice_hi_26350769.wav\n",
            "Saved: common_voice_hi_27478709.wav\n",
            "Saved: common_voice_hi_26351083.wav\n",
            "Saved: common_voice_hi_25437226.wav\n",
            "Saved: common_voice_hi_26369383.wav\n",
            "Saved: common_voice_hi_25154438.wav\n",
            "Saved: common_voice_hi_27546040.wav\n",
            "Saved: common_voice_hi_24228548.wav\n",
            "Saved: common_voice_hi_26619798.wav\n",
            "Saved: common_voice_hi_27478451.wav\n",
            "Saved: common_voice_hi_28223307.wav\n",
            "Saved: common_voice_hi_25189033.wav\n",
            "Saved: common_voice_hi_40152488.wav\n",
            "Saved: common_voice_hi_26080939.wav\n",
            "Saved: common_voice_hi_24977127.wav\n",
            "Saved: common_voice_hi_27517914.wav\n",
            "Saved: common_voice_hi_27509110.wav\n",
            "Saved: common_voice_hi_24225356.wav\n",
            "\n",
            "Summary:\n",
            "Saved files: 100\n",
            "Skipped files: 0\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import torchaudio\n",
        "from silero_vad import get_speech_timestamps\n",
        "\n",
        "DATA_DIR = \"hi_test_dataset/audio+transcripts\"\n",
        "OUT_DIR = \"/content/processed_wav\"\n",
        "\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "\n",
        "mp3_files = [f for f in os.listdir(DATA_DIR) if f.lower().endswith(\".mp3\")]\n",
        "\n",
        "print(\"Total mp3 files:\", len(mp3_files))\n",
        "\n",
        "saved_count = 0\n",
        "skipped_count = 0\n",
        "\n",
        "for fname in mp3_files:\n",
        "    in_path = os.path.join(DATA_DIR, fname)\n",
        "    out_name = fname.replace(\".mp3\", \".wav\")\n",
        "    out_path = os.path.join(OUT_DIR, out_name)\n",
        "\n",
        "    # load\n",
        "    waveform, sr = torchaudio.load(in_path)\n",
        "\n",
        "    if waveform.shape[0] > 1:\n",
        "        waveform = waveform.mean(dim=0, keepdim=True)\n",
        "\n",
        "    if sr != 16000:\n",
        "        waveform = torchaudio.functional.resample(waveform, sr, 16000)\n",
        "        sr = 16000\n",
        "\n",
        "    # gentle VAD\n",
        "    speech_ts = get_speech_timestamps(\n",
        "        waveform,\n",
        "        vad_model,\n",
        "        sampling_rate=16000,\n",
        "        threshold=0.2,\n",
        "        min_speech_duration_ms=50,\n",
        "        min_silence_duration_ms=300\n",
        "    )\n",
        "\n",
        "    if len(speech_ts) == 0:\n",
        "        skipped_count += 1\n",
        "        print(\"Skipped (no speech):\", fname)\n",
        "        continue\n",
        "\n",
        "    speech_audio = torch.cat(\n",
        "        [waveform[:, s[\"start\"]:s[\"end\"]] for s in speech_ts],\n",
        "        dim=1\n",
        "    )\n",
        "\n",
        "    torchaudio.save(out_path, speech_audio, 16000)\n",
        "    saved_count += 1\n",
        "    print(\"Saved:\", out_name)\n",
        "\n",
        "print(\"\\nSummary:\")\n",
        "print(\"Saved files:\", saved_count)\n",
        "print(\"Skipped files:\", skipped_count)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RBw9z15SNq9K"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "\n",
        " All 100 .mp3 files were found\n",
        " All were loaded correctly\n",
        " Resampling to 16 kHz worked\n",
        " Gentle Silero VAD detected speech correctly\n",
        " Silence was removed\n",
        " Processed files were saved\n",
        " Output folder is correct\n",
        "\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install noisereduce"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "KjJf0PoFC-fy",
        "outputId": "02bed833-729d-4aca-f38b-0b7ac4e0c6f4"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting noisereduce\n",
            "  Downloading noisereduce-3.0.3-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from noisereduce) (1.16.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from noisereduce) (3.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from noisereduce) (2.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from noisereduce) (4.67.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from noisereduce) (1.5.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->noisereduce) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->noisereduce) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->noisereduce) (4.61.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->noisereduce) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->noisereduce) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->noisereduce) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->noisereduce) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->noisereduce) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->noisereduce) (1.17.0)\n",
            "Downloading noisereduce-3.0.3-py3-none-any.whl (22 kB)\n",
            "Installing collected packages: noisereduce\n",
            "Successfully installed noisereduce-3.0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RizgbKN9Nq6o",
        "outputId": "e490ab97-43a5-47ab-ceea-ad0c1e055913"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total WAV files: 102\n",
            "Saved: common_voice_hi_26018159.wav\n",
            "Saved: common_voice_hi_24969673.wav\n",
            "Saved: common_voice_hi_23809919.wav\n",
            "\n",
            "Summary:\n",
            "Cleaned files saved: 102\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import torchaudio\n",
        "import noisereduce as nr\n",
        "\n",
        "# paths\n",
        "IN_DIR = \"/content/processed_wav\"\n",
        "OUT_DIR = \"/content/processed_wav_clean\"\n",
        "\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "\n",
        "wav_files = [f for f in os.listdir(IN_DIR) if f.endswith(\".wav\")]\n",
        "\n",
        "print(\"Total WAV files:\", len(wav_files))\n",
        "\n",
        "saved_count = 0\n",
        "\n",
        "for fname in wav_files:\n",
        "    in_path = os.path.join(IN_DIR, fname)\n",
        "    out_path = os.path.join(OUT_DIR, fname)\n",
        "\n",
        "    # load\n",
        "    waveform, sr = torchaudio.load(in_path)\n",
        "\n",
        "    # --- Noise Reduction (light) ---\n",
        "    audio_np = waveform.numpy().squeeze()\n",
        "    clean_np = nr.reduce_noise(\n",
        "        y=audio_np,\n",
        "        sr=sr,\n",
        "        prop_decrease=0.7   # light, safe\n",
        "    )\n",
        "\n",
        "    clean_wave = torch.tensor(clean_np).unsqueeze(0)\n",
        "\n",
        "    # --- Loudness Normalization ---\n",
        "    max_val = clean_wave.abs().max()\n",
        "    if max_val > 0:\n",
        "        clean_wave = clean_wave / max_val * 0.95  # prevent clipping\n",
        "\n",
        "    # save\n",
        "    torchaudio.save(out_path, clean_wave, sr)\n",
        "    saved_count += 1\n",
        "\n",
        "    if saved_count <= 3:\n",
        "        print(\"Saved:\", fname)\n",
        "\n",
        "print(\"\\nSummary:\")\n",
        "print(\"Cleaned files saved:\", saved_count)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Remove wrong whisper package\n",
        "!pip uninstall -y whisper\n",
        "\n",
        "# 2. Install correct OpenAI Whisper\n",
        "!pip install -U openai-whisper\n",
        "\n",
        "# 3. Restart import cache (important)\n",
        "import importlib, sys\n",
        "sys.modules.pop(\"whisper\", None)\n",
        "\n",
        "# 4. Test correct import\n",
        "import whisper\n",
        "print(\"Whisper loaded from:\", whisper.__file__)\n",
        "\n",
        "# 5. Test model loading\n",
        "model = whisper.load_model(\"small\")\n",
        "print(\"Whisper model loaded successfully\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "f7ruOorsDax1",
        "outputId": "b5f5632e-ef1e-49bc-ec06-15bdb93c2233"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping whisper as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: openai-whisper in /usr/local/lib/python3.12/dist-packages (20250625)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (10.8.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (0.60.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (2.0.2)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (0.12.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (2.9.0+cu126)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (4.67.1)\n",
            "Requirement already satisfied: triton>=2 in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (3.5.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba->openai-whisper) (0.43.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken->openai-whisper) (2025.11.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from tiktoken->openai-whisper) (2.32.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (1.11.1.6)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2025.11.12)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->openai-whisper) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->openai-whisper) (3.0.3)\n",
            "Whisper loaded from: /usr/local/lib/python3.12/dist-packages/whisper/__init__.py\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████████████| 461M/461M [00:07<00:00, 61.8MiB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Whisper model loaded successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pG9vLGzWQgJK",
        "outputId": "e40ebaf3-e75d-42fb-e192-99b4e08da691"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total files to transcribe: 102\n",
            "Sample 1: TEST_RESAMPLED.wav | करीना के लाडले बेटे तैमूर को खाने में पसंद है ये खास जीज\n",
            "Sample 2: TEST_VAD.wav | करीना के लाडले बेटे तैमूर को खाने में पसंद है ये खास जीज\n",
            "Sample 3: common_voice_hi_23795243.wav | यह साई सब से अची हैं\n",
            "\n",
            "Saved transcripts to: /content/text/predicted_transcripts.txt\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import whisper\n",
        "\n",
        "# paths\n",
        "IN_DIR = \"/content/processed_wav_clean\"\n",
        "OUT_TXT =\"/content/text/predicted_transcripts.txt\"\n",
        "\n",
        "# load whisper model\n",
        "model = whisper.load_model(\"small\")  # stable for Hindi\n",
        "\n",
        "wav_files = sorted([f for f in os.listdir(IN_DIR) if f.endswith(\".wav\")])\n",
        "\n",
        "print(\"Total files to transcribe:\", len(wav_files))\n",
        "\n",
        "with open(OUT_TXT, \"w\", encoding=\"utf-8\") as out_f:\n",
        "    for i, fname in enumerate(wav_files, 1):\n",
        "        wav_path = os.path.join(IN_DIR, fname)\n",
        "\n",
        "        result = model.transcribe(\n",
        "            wav_path,\n",
        "            language=\"hi\",\n",
        "            task=\"transcribe\",\n",
        "            temperature=0.0,\n",
        "            beam_size=5\n",
        "        )\n",
        "\n",
        "        text = result[\"text\"].strip()\n",
        "\n",
        "        out_f.write(f\"{fname} | {text}\\n\")\n",
        "\n",
        "        if i <= 3:\n",
        "            print(f\"Sample {i}: {fname} | {text}\")\n",
        "\n",
        "print(\"\\nSaved transcripts to:\", OUT_TXT)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install jiwer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "krH0m5ETF27M",
        "outputId": "7e67e0e3-4c07-42fe-88d6-febcac756266"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting jiwer\n",
            "  Downloading jiwer-4.0.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: click>=8.1.8 in /usr/local/lib/python3.12/dist-packages (from jiwer) (8.3.1)\n",
            "Collecting rapidfuzz>=3.9.7 (from jiwer)\n",
            "  Downloading rapidfuzz-3.14.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (12 kB)\n",
            "Downloading jiwer-4.0.0-py3-none-any.whl (23 kB)\n",
            "Downloading rapidfuzz-3.14.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (3.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m40.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rapidfuzz, jiwer\n",
            "Successfully installed jiwer-4.0.0 rapidfuzz-3.14.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from jiwer import wer\n",
        "import re\n",
        "\n",
        "# ---- PATHS ----\n",
        "GT_TXT = \"/content/hi_test_dataset/audio+transcripts/transcripts.txt\"\n",
        "PRED_TXT = \"/content/text/predicted_transcripts.txt\"\n",
        "\n",
        "# ---- HINDI NORMALIZATION ----\n",
        "def normalize_hi(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r\"[।?,!\\\"']\", \"\", text)\n",
        "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
        "    return text\n",
        "\n",
        "# ---- LOAD TRANSCRIPTS ----\n",
        "def load_txt(path):\n",
        "    data = {}\n",
        "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "        for line in f:\n",
        "            if \"|\" not in line:\n",
        "                continue\n",
        "            fname, text = line.strip().split(\"|\", 1)\n",
        "            data[fname.strip()] = text.strip()\n",
        "    return data\n",
        "\n",
        "gt = load_txt(GT_TXT)\n",
        "pred = load_txt(PRED_TXT)\n",
        "\n",
        "# ---- WER CALCULATION ----\n",
        "wers = []\n",
        "\n",
        "for fname in gt:\n",
        "    wav_name = fname.replace(\".mp3\", \".wav\")  # important mapping\n",
        "\n",
        "    if wav_name not in pred:\n",
        "        continue\n",
        "\n",
        "    ref = normalize_hi(gt[fname])\n",
        "    hyp = normalize_hi(pred[wav_name])\n",
        "\n",
        "    score = wer(ref, hyp)\n",
        "    wers.append(score)\n",
        "\n",
        "# ---- FINAL RESULT ----\n",
        "avg_wer = sum(wers) / len(wers)\n",
        "\n",
        "print(\"Total files evaluated:\", len(wers))\n",
        "print(\"Average WER:\", round(avg_wer, 3))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sqLXI78oFOX1",
        "outputId": "be7cd919-9542-45f9-9505-b151949bdea3"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total files evaluated: 100\n",
            "Average WER: 0.587\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from jiwer import cer\n",
        "import re\n",
        "\n",
        "# ---- PATHS ----\n",
        "GT_TXT = \"/content/hi_test_dataset/audio+transcripts/transcripts.txt\"\n",
        "PRED_TXT = \"/content/text/predicted_transcripts.txt\"\n",
        "\n",
        "# ---- HINDI NORMALIZATION (light, safe) ----\n",
        "def normalize_hi(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r\"[।?,!\\\"']\", \"\", text)\n",
        "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
        "    return text\n",
        "\n",
        "# ---- LOAD TEXT FILES ----\n",
        "def load_txt(path):\n",
        "    data = {}\n",
        "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "        for line in f:\n",
        "            if \"|\" not in line:\n",
        "                continue\n",
        "            fname, text = line.strip().split(\"|\", 1)\n",
        "            data[fname.strip()] = text.strip()\n",
        "    return data\n",
        "\n",
        "gt = load_txt(GT_TXT)\n",
        "pred = load_txt(PRED_TXT)\n",
        "\n",
        "# ---- CER CALCULATION ----\n",
        "cers = []\n",
        "\n",
        "for fname in gt:\n",
        "    wav_name = fname.replace(\".mp3\", \".wav\")  # mapping\n",
        "\n",
        "    if wav_name not in pred:\n",
        "        continue\n",
        "\n",
        "    ref = normalize_hi(gt[fname])\n",
        "    hyp = normalize_hi(pred[wav_name])\n",
        "\n",
        "    score = cer(ref, hyp)\n",
        "    cers.append(score)\n",
        "\n",
        "# ---- FINAL RESULT ----\n",
        "avg_cer = sum(cers) / len(cers)\n",
        "\n",
        "print(\"Total files evaluated:\", len(cers))\n",
        "print(\"Average CER:\", round(avg_cer, 3))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yjNmZBbxJAc3",
        "outputId": "eb37fc71-819d-4af0-a0d3-22b3c6912045"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total files evaluated: 100\n",
            "Average CER: 0.317\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# ---- PATHS ----\n",
        "GT_TXT = \"/content/hi_test_dataset/audio+transcripts/transcripts.txt\"\n",
        "PRED_TXT = \"/content/text/predicted_transcripts.txt\"\n",
        "\n",
        "# ---- HINDI NORMALIZATION ----\n",
        "def normalize_hi(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r\"[।?,!\\\"']\", \"\", text)\n",
        "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
        "    return text\n",
        "\n",
        "# ---- LOAD FILES ----\n",
        "def load_txt(path):\n",
        "    data = {}\n",
        "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "        for line in f:\n",
        "            if \"|\" not in line:\n",
        "                continue\n",
        "            fname, text = line.strip().split(\"|\", 1)\n",
        "            data[fname.strip()] = text.strip()\n",
        "    return data\n",
        "\n",
        "gt = load_txt(GT_TXT)\n",
        "pred = load_txt(PRED_TXT)\n",
        "\n",
        "# ---- SER CALCULATION ----\n",
        "total = 0\n",
        "wrong = 0\n",
        "\n",
        "for fname in gt:\n",
        "    wav_name = fname.replace(\".mp3\", \".wav\")\n",
        "\n",
        "    if wav_name not in pred:\n",
        "        continue\n",
        "\n",
        "    ref = normalize_hi(gt[fname])\n",
        "    hyp = normalize_hi(pred[wav_name])\n",
        "\n",
        "    total += 1\n",
        "    if ref != hyp:\n",
        "        wrong += 1\n",
        "\n",
        "ser = wrong / total\n",
        "\n",
        "print(\"Total sentences evaluated:\", total)\n",
        "print(\"Sentence Error Rate (SER):\", round(ser, 3))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ZuY7BbYJY0d",
        "outputId": "7ffada69-1dd7-4aa7-f982-9b4c168deb22"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total sentences evaluated: 100\n",
            "Sentence Error Rate (SER): 0.97\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}